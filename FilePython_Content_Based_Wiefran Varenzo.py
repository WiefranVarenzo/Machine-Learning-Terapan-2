# -*- coding: utf-8 -*-
"""Content_based_final4_Last.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BiPa8h2lpPe6Lbvfj_y7vo27KeZHTlEN

# **Recommendation System: Retail Global Fashion Retail Sales**

*   Nama    : Wiefran Varenzo
*   Email   : lionwiefran88@gmail.com
*   Username: Wiefran Varenzo

Proyek ini bertujuan untuk: Melakukan rekomendasi menggunakan metode Content-Based yang bertujuan untuk mengefisiensikan penjualan produk fashion untuk retail ataupun e-commerce

# **1. Memuat Library dan Dataset**

## **Gambaran Umum Dataset****

Dataset ini diambil dari [Kaggle Repository](https://www.kaggle.com/datasets/ricgomes/global-fashion-retail-stores-dataset?select=transactions.csv) dengan judul:
**"Global Fashion Retail Sales"**

---



Berikut pembagian atribut ke dalam 4 kelompok dataset yang lebih terpisah dan terstruktur, lengkap dengan **tipe data** tiap kolom:

---

### **Transaksi (Sales Transaction Dataset)**

Berisi data transaksi individual pelanggan.

| Kolom            | Deskripsi                                           | Tipe Data       |
| ---------------- | --------------------------------------------------- | --------------- |
| Invoice ID       | ID unik untuk transaksi                             | `string`        |
| Line             | Nomor urut item dalam invoice                       | `int`           |
| Customer ID      | ID unik pelanggan                                   | `string`        |
| Product ID       | ID unik produk                                      | `string`        |
| Size             | Ukuran produk (S, M, L, XL, atau kosong)            | `string / null` |
| Color            | Warna produk (versi transaksi)                      | `string`        |
| Unit Price       | Harga satuan produk sebelum diskon                  | `float`         |
| Quantity         | Jumlah unit dibeli                                  | `int`           |
| Date             | Tanggal dan waktu transaksi                         | `datetime`      |
| Discount         | Diskon (misalnya 0.2 berarti 20%)                   | `float`         |
| Line Total       | Total harga line item setelah diskon                | `float`         |
| Store ID         | ID toko tempat transaksi                            | `string`        |
| Employee ID      | ID karyawan yang memproses transaksi                | `string`        |
| Currency         | Kode mata uang (3 huruf)                            | `string`        |
| Currency Symbol  | Simbol mata uang                                    | `string`        |
| SKU              | Gabungan Product ID, Size, dan Color                | `string`        |
| Transaction Type | Jenis transaksi (Sale, Return)                      | `category`      |
| Payment Method   | Metode pembayaran                                   | `category`      |
| Invoice Total    | Total invoice (sama untuk setiap baris per invoice) | `float`         |

---

### **Pelanggan (Customer Dataset)**

Berisi informasi demografis pelanggan.

| Kolom         | Deskripsi               | Tipe Data  |
| ------------- | ----------------------- | ---------- |
| Customer ID   | ID unik pelanggan       | `string`   |
| Name          | Nama pelanggan          | `string`   |
| Email         | Email pelanggan         | `string`   |
| Telephone     | Nomor telepon pelanggan | `string`   |
| City          | Kota pelanggan          | `string`   |
| Country       | Negara pelanggan        | `string`   |
| Gender        | Jenis kelamin (F, M, D) | `category` |
| Date Of Birth | Tanggal lahir pelanggan | `date`     |
| Job Title     | Pekerjaan pelanggan     | `string`   |
| Age           | Umur pelanggan          | `int`      |

---

### **Produk (Product Dataset)**

Berisi informasi produk dan deskripsinya.

| Kolom           | Deskripsi                   | Tipe Data      |
| --------------- | --------------------------- | -------------- |
| Product ID      | ID unik produk              | `string`       |
| Category        | Kategori produk utama       | `string`       |
| Sub Category    | Subkategori produk          | `string`       |
| Description PT  | Deskripsi produk (Portugis) | `string`       |
| Description DE  | Deskripsi produk (Jerman)   | `string`       |
| Description FR  | Deskripsi produk (Perancis) | `string`       |
| Description ES  | Deskripsi produk (Spanyol)  | `string`       |
| Description EN  | Deskripsi produk (Inggris)  | `string`       |
| Description ZH  | Deskripsi produk (Mandarin) | `string`       |
| Color           | Warna produk (versi produk) | `string`       |
| Sizes           | Ukuran produk yang tersedia | `list<string>` |
| Production Cost | Biaya produksi dalam USD    | `float`        |

---

### **Toko (Store Dataset)**

Berisi informasi geografis dan operasional tiap toko.

| Kolom               | Deskripsi                        | Tipe Data |
| ------------------- | -------------------------------- | --------- |
| Store ID            | ID toko                          | `string`  |
| Store Name          | Nama toko                        | `string`  |
| Number of Employees | Jumlah karyawan di toko          | `int`     |
| ZIP Code            | Kode pos toko                    | `string`  |
| City                | Kota toko                        | `string`  |
| Country             | Negara toko                      | `string`  |
| Latitude            | Koordinat lintang toko           | `float`   |
| Longitude           | Koordinat bujur toko             | `float`   |
| Country\_English    | Nama negara dalam bahasa Inggris | `string`  |

## **Import Libary**

Disini, saya melakukan mengimport pustaka yang dipakai, disini karena saya menggunakan TF-IDF maka library yang dipakai adalah TfidfVectorizer, kemudian, disini juga menggunakan cosine_similarity serta NearestNeighbors. Semua library ini di import di awal agar kode lebih mudah dilihat (library mana yang dipakai)
"""

from datetime import datetime
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neighbors import NearestNeighbors
from sklearn.decomposition import PCA, TruncatedSVD
from sklearn.metrics.pairwise import cosine_similarity
import requests
import zipfile
import io
from google.colab import files

"""## **Memuat Dataset**

Disini kita harus mengupload file Kaggle.json agar memiliki izin untuk mendownload dari website kaggle
"""

files.upload()

"""Disini kita akan menyambungkan kaggle dengan colab"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

"""Disini, kita ingin mendownload dataset kaggle dengan Kaggle download from CLI"""

!kaggle datasets download ricgomes/global-fashion-retail-stores-dataset

"""Disini, saya membuat direktori baru dengan nama global-fashion-retail-stores-dataset, setelah itu hasil download yang berupa zip akan di unsip dan dimasukkan ke direktori global-fashion-retail-stores-dataset"""

!mkdir global-fashion-retail-stores-dataset
!unzip global-fashion-retail-stores-dataset.zip -d global-fashion-retail-stores-dataset

"""Setiap dataset csv akan di muat ke variabel dengan pustaka dari pandas, yaitu fungsi read_csv()"""

customers = pd.read_csv('/content/global-fashion-retail-stores-dataset/customers.csv')
products = pd.read_csv('/content/global-fashion-retail-stores-dataset/products.csv')
stores = pd.read_csv('/content/global-fashion-retail-stores-dataset/stores.csv')
transactions = pd.read_csv('/content/global-fashion-retail-stores-dataset/transactions.csv')

"""Saya hanya menggunakan 4 dataset dari 6 dataset, dikarenakan untuk dataset Employees dan Discount tidak terlalu dibutuhkan, sebab yang yang lebih difokuskan disini adalah customer, produk, toko, serta transaksi yang terjadi (dalam hal recommendation system)

# **2. Data Understanding and EDA (Exploratory Data Analysis)**

## **Customer**
"""

customers.head()

"""Disini bisa kita lihat, bahwa ada beberapa data NaN, namun untuk bentuk datanya sendiri kebanyakan bertipe string/object yang memiliki informasi mengenai customer dari toko retail fashion"""

print('Jumlah data pelanggan: ', len(customers['Customer ID'].unique()))

"""Jumlah pelanggan yang kita miliki informasi berkitar 1,64 juta orang customer."""

customers.info()

"""Dari informasi yang bisa kita dapatkan, bahwa ada ketidak samaan untuk jumlah data Job Title dibandingkan kolom lainnya. Kemudian, untuk tipe data dari Date Of Birth seharusnya adalah bertipe 'DateTime'"""

customers.isnull().sum()

"""Ternyata memang terdapat data null di kolom Job Title, sebanyak 584185 data null yang nanti harus kita bersihkan"""

customers.duplicated().sum()

"""Tidak ditemukan adanya data yang duplikat di dataset customers."""

# Memastikan kolom Date Of Birth menjadi date
customers['Date Of Birth'] = pd.to_datetime(customers['Date Of Birth'], errors='coerce')

# Hitung usia (Age)
today = pd.to_datetime('today')
customers['Age'] = customers['Date Of Birth'].apply(lambda dob: (today.year - dob.year - ((today.month, today.day) < (dob.month, dob.day))) if pd.notnull(dob) else None)

"""Disini, saya mengubah aja langsung untuk tipe data Date Of Birth agar nantinya mempermudah proses preprocessing"""

# Distribusi Gender
sns.countplot(data=customers, x='Gender')
plt.title("Distribusi Gender Pelanggan")
plt.show()

"""Dataset ini memiliki data customer bergender M-Male lebih banyak dibandingkan F-Female. Sedangkan Diverse atau selain Wanita atau Pria, itu sangat sedikit."""

# Distribusi Umur
sns.histplot(customers['Age'].dropna(), bins=20, kde=True)
plt.title("Distribusi Umur Pelanggan")
plt.xlabel("Umur")
plt.show()

"""Distribusi cukup dominan dari kalangan orang mudah yang didominasi umur 20 tahunan

## **Products**
"""

products.head()

"""Ini adalah Dataset Product, yang merupakan dataset untuk informasi berkaitan dengan produk yang dijual retail fashion di seluruh dunia."""

print('Jumlah Sub Kategori: ', len(products['Sub Category'].unique()))
print(products['Sub Category'].unique())

"""Ini adalah beberapa sub kategori dari produk yang di jual di retail fashion, terdapat 21 sub kategori yang berhubungan dengan pakaian dan juga barang fashion lainnya."""

products.info()

"""Disini, bisa kita lilhat terdapat beberapa perbedaan jumlah untuk color dan sizes, tetapi hal ini bisa berindikasi pada pemakaian berulang untuk setiap data color dan sizes yang tetap aman berada di dataset"""

# Distribusi Kategori
sns.countplot(data=products, x='Category', order=products['Category'].value_counts().index)
plt.title("Distribusi Kategori Produk")
plt.xticks(rotation=45)
plt.show()

"""Kategori dataset ini sendiri ada 3 macam yang di dominasi oleh produk berkategori feminime."""

# Distribusi Sub-Kategori
sns.countplot(data=products, x='Sub Category', order=products['Sub Category'].value_counts().index)
plt.title("Distribusi Sub-Kategori Produk")
plt.xticks(rotation=90)
plt.show()

"""Sub Kategori produk yang paling banyak ditemukan adalah Accesories, lalu diikut oleh Pants and jeans, Sportwear, dan coats and Blazers

## **Stores**
"""

stores.head()

"""Untuk dataset Stores, lebih mengarah kepada data toko retail seperti dimana negara dan kota toko itu berada, jumlah karyawan, ataupun zip code daerah."""

print('Jumlah Nama Toko: ', len(stores['Store Name'].unique()))
print(stores['Store Name'].unique())

"""Sekitar 35 toko yang telah didata"""

stores.info()

"""Dari informasi yang diberikan, bisa dilihat bahwa setiap tipe data sudah baik, dan sesuai."""

stores.Country.unique()

# Mapping nama negara agar semuanya pakai Latin characters
country_map = {
    'United States': 'United States',
    '中国': 'China',
    'Deutschland': 'Germany',
    'United Kingdom': 'United Kingdom',
    'France': 'France',
    'España': 'Spain',
    'Portugal': 'Portugal'
}

# Buat kolom baru hasil mapping
stores['Country_English'] = stores['Country'].map(country_map)

# Plot menggunakan kolom Country_English
sns.countplot(data=stores, x='Country_English', order=stores['Country_English'].value_counts().index)
plt.title("Jumlah Toko per Negara")
plt.xticks(rotation=45)
plt.show()

"""Penetapan langsung nama negara dari setiap toko, itu bertujuan agar mengurangi ketidak jelasan pada nama, terutama untuk nama china yang tidak akan dikenali oleh Colab, sehingga secara manual melakukan penamaan negara bisa mengurangi eror yang terjadi pada penamaan.

## **Transactions**
"""

transactions.head()

print('Jumlah data transaksi: ', len(transactions['Invoice ID'].unique()))

"""Penamaan dataset transaksi berkisar 4,5 juta transaksi yang bisa di telaah dengan baik. Perhitungan ini dilakukan dengan menghitung Invoice ID agar bisa secara unik menghitung transaksi yang telah dilakukan"""

transactions.info()

"""Untuk data transaksi terdiri dari 19 kolom yang semuanya berkaitan dengan transaksi yang dilakukan oleh customer."""

# Distribusi Metode Pembayaran
sns.countplot(data=transactions, x='Payment Method', order=transactions['Payment Method'].value_counts().index)
plt.title("Distribusi Metode Pembayaran")
plt.show()

"""Untuk distribusi metode pembayaran, credit card disini sangat mendominasi metode pembayaran yang dilakukan. Sedangkan untuk metode pembayaran cash sendiri, tidak sampai 30% dari total pembayaran"""

# Distribusi apakah barang terjual atau dikembalikan
sns.countplot(data=transactions, x='Transaction Type')
plt.title("Distribusi sales or return")
plt.show()

"""Lalu, dari grafik ini, bisa kita lihat bahwa barang yang dikembalikan sangat sedikit."""

# Memastikan kolom 'Date' menjadi datetime
transactions['Date'] = pd.to_datetime(transactions['Date'])

# Penjualan Harian
daily_sales = transactions.groupby(transactions['Date'].dt.date)['Line Total'].sum().reset_index()

# Visualisasi
plt.figure(figsize=(12, 6))
sns.lineplot(data=daily_sales, x='Date', y='Line Total')
plt.title("Total Penjualan per Hari")
plt.xlabel("Tanggal")
plt.ylabel("Total Penjualan")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""Kita bisa melihat bahwa terjadi beberapa lonjakan penjualan, terutama untuk yang berdekatan dengan januari (sebelum januari tahun depan) yang mengindikasikan berdekatan dengan natal, penjualan fashion meningkat cukup signifikan"""

# Korelasi Numerik
plt.figure(figsize=(10,6))
corr = transactions[['Unit Price', 'Quantity', 'Discount', 'Line Total', 'Invoice Total']].corr()
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')
plt.title("Korelasi Fitur Numerik Transaksi")
plt.show()

"""Kita dapat melihat bahwa Unit Price dan Line Total memiliki korelasi positif yang sangat kuat, begitu juga antara Invoice Total dan Line Total. Selain itu, terdapat korelasi yang cukup tinggi antara Invoice Total dan Unit Price.Hal ini mengindikasikan bahwa harga satuan (unit price) memainkan peran penting dalam menentukan nilai total transaksi, baik pada tingkat item (line total) maupun keseluruhan invoice (invoice total). Dengan kata lain, semakin tinggi harga satuan suatu produk, semakin besar kemungkinan total nilai transaksi juga meningkat, terutama jika jumlah pembelian (quantity) dan diskon tetap atau tidak bervariasi secara ekstrem."""

# Gabungkan transactions dengan products untuk mendapatkan deskripsi produk
transactions_with_desc = transactions.merge(products[['Product ID', 'Sub Category']], on='Product ID', how='left')

# Produk Terlaris berdasarkan Quantity
top_products = (
    transactions_with_desc.groupby('Sub Category')['Quantity']
    .sum()
    .sort_values(ascending=False)
    .head(10)
)

plt.figure(figsize=(12, 6))
top_products.plot(kind='bar', title="Top 10 Produk Terlaris", color='skyblue')
plt.xlabel("Deskripsi Produk")
plt.ylabel("Jumlah Terjual")
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

"""Dalam data transaksi ini, kita dapat melihat bahwa terdapat 10 produk terlaris, di antaranya adalah Pants and Jeans, Sportswear, dan lainnya.
Beberapa kategori seperti Dresses and Jumpsuits, T-shirts and Polos, Shirts and Blouses, Sweaters-Sweatshirts, serta Sweaters and Knitwear menunjukkan jumlah penjualan yang hampir setara, yang mengindikasikan bahwa kategori-kategori tersebut memiliki tingkat permintaan yang relatif merata di antara konsumen.


"""

# Produk dengan Pendapatan Tertinggi berdasarkan Line Total
top_revenue_products = (
    transactions_with_desc.groupby('Sub Category')['Line Total']
    .sum()
    .sort_values(ascending=False)
    .head(10)
)

plt.figure(figsize=(12, 6))
top_revenue_products.plot(kind='bar', title="Top 10 Produk Berpendapatan Tertinggi", color='seagreen')
plt.xlabel("Deskripsi Produk")
plt.ylabel("Total Pendapatan")
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

"""Coats and Blazers dan pants-jeans adalah produk yang mendatangkan pendapatan paling tinggi, hal ini bisa terjadi karena memang kedua produk ini terjual paling banyak dari produk lainnya. Namun yang menariknya suits and blazers tidak ada pada top 10 paling banyak terjual, tetapi menjadi top 3 barang yang membawa pendapatan tertinggi. Hal ini bisa dikarenakan harga barang saat terjual jauh lebih tinggi dari produk lainnya.

# **3. Data Preprocessing dan Data Preparation**

## **Mengatasi Data Null dan Duplikat**
"""

customers = customers.dropna(axis=0, how='any')        # Hapus baris dengan nilai null
customers = customers.drop_duplicates()                # Hapus duplikat seluruh baris

"""Disini, saya menghapus baris null dan duplikat untuk dataset customer"""

products = products.dropna(axis=0, how='any')          # Hapus baris dengan nilai null
products = products.drop_duplicates()

"""Disini, saya menghapus baris null dan duplikat untuk dataset products"""

stores = stores.dropna(axis=0, how='any')
stores = stores.drop_duplicates()

"""Disini, saya menghapus baris null dan duplikat untuk dataset stores"""

transactions = transactions.dropna(axis=0, how='any')
transactions = transactions.drop_duplicates()

"""Disini, saya menghapus baris null dan duplikat untuk dataset transactions"""

transactions = transactions.dropna(subset=['Customer ID', 'Product ID', 'Store ID', 'Quantity'])

"""Disini, saya kembali memastikan bahwa untuk kolom-kolom penting yang nanti akan dipakai tidak memiliki data null

## **Menggabungkan seluruh data berdasarkan ID masing-masing dataset**
"""

# Merge hanya yang match (tanpa NULL)
df = transactions.merge(customers, on='Customer ID', how='inner') \
                 .merge(products, on='Product ID', how='inner') \
                 .merge(stores, on='Store ID', how='inner')

"""Disini, saya menggabungkan dataset transactions dengan dataset customers, products, dan stores, yang di merge dengan metode inner join, sehingga yang menggabungkan setiap ID dengan dataset transactions"""

print(df.info())         # Lihat struktur & null
print(df.isnull().sum()) # Cek sisa null per kolom

"""Dari sini kita bisa melihat bahwa tidak ada data null sama sekali untuk dataset gabungan.

## **Mengambil data yang hanya diperlukan untuk Collaborative Filtering**
"""

# Kolom-kolom yang dibutuhkan untuk CF dan CBF
df = df[['Customer ID',
         'Product ID',
         'Store Name',
         'Quantity',
         'Line Total',
         'Date',
         'Category',
         'Sub Category',
         'Color_y',
         'Sizes',
         'Description EN',
         'Production Cost'
        ]]

df

df = df.drop_duplicates(subset=['Product ID'])

"""# **4. Model Development dengan Content Based Filtering (TF-IDF dan NeareNearestNeighbors)**"""

df = df.reset_index(drop=True)

# Mengkombinasikan text features
df['combined_features'] = df['Category'].astype(str) + ' ' + \
                          df['Sub Category'].astype(str) + ' ' + \
                          df['Color_y'].astype(str) + ' ' + \
                          df['Sizes'].astype(str) + ' ' + \
                          df['Description EN'].astype(str)

# TF-IDF
tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(df['combined_features'])

print("TF-IDF matrix shape:", tfidf_matrix.shape)

"""Pada sel ini, kita menggabungkan beberapa atribut teks dari data produk seperti kategori, subkategori, warna, ukuran, dan deskripsi ke dalam satu kolom combined_features, lalu menerapkan teknik TF-IDF (Term Frequency-Inverse Document Frequency) untuk mengubah teks tersebut menjadi representasi numerik. Hasilnya adalah matriks TF-IDF berukuran (5358, 210), yang berarti terdapat 5358 produk unik dan 210 fitur kata unik yang dipertimbangkan. Matriks ini berguna untuk menghitung kemiripan antar produk sebagai dasar dalam sistem rekomendasi berbasis konten."""

# Map Product ID to DataFrame index
product_id_to_index = pd.Series(df.index, index=df['Product ID'])

# Nearest Neighbors model
model = NearestNeighbors(n_neighbors=5 + 20, metric='cosine', algorithm='brute')
model.fit(tfidf_matrix)

"""Kode NearestNeighbors(algorithm='brute', metric='cosine', n_neighbors=25) digunakan untuk membuat model rekomendasi berbasis konten yang mencari 25 produk paling mirip berdasarkan deskripsi dan atribut produk. Model ini menggunakan algoritma brute-force untuk menghitung kemiripan antar produk dan memakai metrik cosine similarity yang fokus pada arah fitur teks (bukan besar nilainya), sehingga cocok digunakan bersama TF-IDF untuk merepresentasikan konten produk."""

def get_recommendations_with_similarity(product_id, top_n=5):
    if product_id not in product_id_to_index:
        return f"Product ID {product_id} not found."

    idx = product_id_to_index[product_id]
    sim_scores = list(enumerate(cosine_similarity(tfidf_matrix[idx], tfidf_matrix)[0]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    original_description = df.iloc[idx]['Description EN']
    original_product_id = df.iloc[idx]['Product ID']

    recommendations = []
    sim_list = []

    for i, score in sim_scores[1:]:  # skip self
        current_product_id = df.iloc[i]['Product ID']
        current_description = df.iloc[i]['Description EN']

        if current_product_id != original_product_id and current_description != original_description:
            recommendations.append(df.iloc[i])
            sim_list.append((current_product_id, score))

        if len(recommendations) == top_n:
            break

    # Visualisasi skor kemiripan
    plt.figure(figsize=(6, 3))
    sns.barplot(x=list(range(len(sim_list))), y=[s[1] for s in sim_list])
    plt.title(f"TF-IDF Cosine Similarity to Product {product_id}")
    plt.ylabel("Similarity")
    plt.xlabel("Recommendation Rank")
    plt.ylim(0, 1)
    plt.show()

    return pd.DataFrame(recommendations)[['Product ID', 'Category', 'Sub Category', 'Description EN', 'Color_y']]

"""Fungsi get_recommendations ini digunakan untuk merekomendasikan produk yang mirip dengan produk tertentu berdasarkan konten deskriptifnya. Fungsi ini mencari indeks produk dari ID yang diberikan, lalu menghitung kemiripan (cosine distance) menggunakan model NearestNeighbors pada matriks TF-IDF, menyaring hasil yang duplikat, dan menampilkan top_n produk paling mirip. Selain itu, fungsi ini juga memvisualisasikan seberapa dekat (mirip) setiap rekomendasi terhadap produk awal menggunakan barplot, lalu mengembalikan DataFrame berisi detail produk yang direkomendasikan."""

distances, indices = model.kneighbors(tfidf_matrix[0], n_neighbors=6)
print("Indices:", indices)
print("Distances:", distances)

"""Kode ini menggunakan model NearestNeighbors untuk mencari 6 produk terdekat (termasuk dirinya sendiri) dari produk pada indeks 0 berdasarkan kemiripan konten (TF-IDF). Output indices menunjukkan indeks produk-produk terdekat dalam dataset, sedangkan distances menunjukkan nilai cosine distance-nya, di mana 0 berarti identik dan semakin besar angkanya berarti semakin tidak mirip. Nilai-nilai ini digunakan untuk mengukur seberapa mirip produk lain terhadap produk referensi secara tekstual."""

# penggunaan dari recommendation System
example_id = df['Product ID'].iloc[0]
print("Original Product Description:\n", df[df['Product ID'] == example_id]['Description EN'].values[0])

recs = get_recommendations_with_similarity(product_id=example_id, top_n=5)
print("\nRecommended Products:")
print(recs)

# Fitur Penting dari TF-IDF
idx = product_id_to_index[example_id]
row = tfidf_matrix[idx].toarray()[0]
feature_names = tfidf.get_feature_names_out()
top_n_words = np.argsort(row)[::-1][:10]
print("\nTop words in TF-IDF vector for product:")
print([feature_names[i] for i in top_n_words])

"""Kode ini menampilkan contoh penggunaan sistem rekomendasi berbasis TF-IDF dan Nearest Neighbors. Pertama, kode menampilkan deskripsi produk asli, lalu memanggil fungsi get_recommendations() untuk menunjukkan 5 produk paling mirip secara konten. Kemudian, kode mengekstrak vektor TF-IDF dari produk tersebut dan menampilkan 10 kata terpenting yang paling membedakan produk tersebut dari yang lain, berdasarkan skor TF-IDF tertinggi. Ini membantu menjelaskan mengapa suatu produk direkomendasikan karena kemiripan kata-kata pentingnya.

# **5. Model Development dengan Content Based Filtering (TF-IDF dan Latent Semantic Analysis (LSA) - TruncatedSVD)**

Latent Semantic Analysis (LSA) adalah metode untuk menemukan pola tersembunyi atau konsep dalam kumpulan teks dengan mereduksi dimensi data teks yang dihasilkan dari TF-IDF. Teknik ini menggunakan Truncated Singular Value Decomposition (TruncatedSVD), yang mirip dengan PCA (Principal Component Analysis) tapi khusus untuk data sparse seperti matriks TF-IDF. LSA membantu mengelompokkan kata-kata yang memiliki makna serupa dan memperbaiki kualitas kemiripan teks yang dihitung, sehingga sistem rekomendasi bisa menemukan produk yang relevan walaupun tidak persis menggunakan kata-kata yang sama.
"""

# 2. TF-IDF + LSA
tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(df['combined_features'])

lsa = TruncatedSVD(n_components=100)  # mirip PCA untuk teks
lsa_matrix = lsa.fit_transform(tfidf_matrix)

# 3. Cosine similarity matrix
similarity_matrix = cosine_similarity(lsa_matrix)

# 4. Mapping ID
product_id_to_index = pd.Series(df.index, index=df['Product ID'])

"""Disini, saya membangun sistem rekomendasi berbasis konten menggunakan gabungan TF-IDF dan LSA (Latent Semantic Analysis). Pertama, TfidfVectorizer mengubah fitur teks gabungan setiap produk menjadi representasi numerik berdasarkan pentingnya kata (TF-IDF). Lalu, TruncatedSVD dengan n_components=100 digunakan untuk mereduksi dimensi vektor TF-IDF menjadi representasi laten yang lebih ringkas, mirip seperti PCA tetapi untuk data teks—ini disebut LSA. Selanjutnya, cosine_similarity menghitung tingkat kemiripan antar produk berdasarkan representasi LSA mereka. Terakhir, product_id_to_index membuat pemetaan antara Product ID dan indeks baris untuk memudahkan pencarian produk dalam matriks."""

def get_lsa_recommendations(product_id, top_n=5):
    if product_id not in product_id_to_index:
        return f"Product ID {product_id} not found."

    idx = product_id_to_index[product_id]
    sim_scores = list(enumerate(similarity_matrix[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    recommendations = []
    sim_list = []

    for i, score in sim_scores[1:]:
        if df.iloc[i]['Product ID'] != product_id:
            recommendations.append(df.iloc[i])
            sim_list.append((df.iloc[i]['Product ID'], score))
        if len(recommendations) == top_n:
            break

    # Visualisasi skor kemiripan
    plt.figure(figsize=(6, 3))
    sns.barplot(x=list(range(len(sim_list))), y=[s[1] for s in sim_list])
    plt.title(f"LSA Similarity to Product {product_id}")
    plt.ylabel("Similarity")
    plt.xlabel("Recommendation Rank")
    plt.show()

    # Kembalikan hasil
    return pd.DataFrame(recommendations)[['Product ID', 'Category', 'Sub Category', 'Description EN', 'Color_y']]

"""Fungsi get_lsa_recommendations ini digunakan untuk memberikan rekomendasi produk berdasarkan kemiripan teks yang dihitung menggunakan matriks similarity hasil dari Latent Semantic Analysis (LSA). Fungsi mencari indeks produk berdasarkan product_id, kemudian mengambil skor kemiripan produk lain dengan produk tersebut dan mengurutkannya dari yang paling mirip. Rekomendasi yang diberikan adalah produk-produk dengan skor kemiripan tertinggi selain produk asli, dibatasi sesuai top_n. Selain mengembalikan data rekomendasi, fungsi ini juga menampilkan visualisasi barplot yang memperlihatkan tingkat kemiripan setiap produk yang direkomendasikan terhadap produk asli."""

# penggunaan dari recommendation System
example_id = df['Product ID'].iloc[0]
print("Original Product:\n", df[df['Product ID'] == example_id]['Description EN'].values[0])

recs = get_lsa_recommendations(product_id=example_id, top_n=5)
print("\nRecommended Products:")
print(recs)

"""Ini adalah hasil Rekomendasi model TF-IDF dan LSA, dimana hasil rekomendasi yang ditampilkan sama seperti TF-IDF Nearestneighbors

# **6. Evaluasi dan Kesimpulan**

## **TF-IDF dan Nearest Neighbors**

### **Evaluasi Sistem Rekomendasi Berbasis Konten dengan TF-IDF dan Nearest Neighbors**

* **Ekstraksi fitur teks menggunakan TF-IDF:**

  * Menangkap kata-kata penting dan unik pada deskripsi produk seperti “suede”, “neutral”, “luxurious”.
  * Memberi bobot lebih tinggi pada kata yang spesifik dan jarang muncul, sehingga merepresentasikan karakteristik produk dengan baik.

* **Pengukuran kemiripan dengan Nearest Neighbors dan Cosine Distance:**

  * Menghitung jarak sudut antar vektor fitur untuk mengukur kesamaan produk.
  * Jarak cosine yang lebih kecil menunjukkan kemiripan yang lebih tinggi antara produk.

* **Hasil rekomendasi untuk produk acuan (Produk 64):**

  * Produk dengan jarak cosine terendah sangat relevan, memiliki deskripsi dan fitur yang mirip (misal bahan suede dan nuansa mewah).
  * Produk dengan jarak lebih tinggi menunjukkan perbedaan halus seperti perubahan bahan (nylon) atau kata kunci (executive vs luxurious).

* **Visualisasi jarak cosine:**

  * Menggambarkan urutan rekomendasi dari yang paling mirip hingga kurang mirip secara bertahap.
  * Membuktikan bahwa sistem merekomendasikan produk secara logis dan berurutan berdasarkan tingkat kemiripan.

### **Kesimpulan:**

  * Sistem rekomendasi berbasis konten ini efektif untuk menemukan produk serupa berdasarkan deskripsi teks.
  * Memiliki potensi pengembangan lebih lanjut, seperti menggabungkan data perilaku pengguna atau memperbaiki preprocessing teks untuk menangani variasi bahasa.

## **TF-IDF dan LSA (Latent Semantic Analysis**

### **Evaluasi Sistem Rekomendasi Berbasis Konten dengan LSA (Latent Semantic Analysis)**

* **Ekstraksi fitur semantik menggunakan LSA:**
    * Melampaui kata kunci harfiah dengan mengidentifikasi **konsep atau topik laten** dalam deskripsi produk (misalnya, konsep "bahan premium" atau "gaya pakaian luar").
    * Menggunakan dekomposisi matriks (SVD) untuk memahami hubungan antar kata, sehingga dapat mengenali bahwa "jaket" dan "mantel" memiliki makna yang berdekatan.

* **Pengukuran kemiripan dalam ruang konseptual LSA:**
    * Membandingkan vektor produk dalam ruang LSA yang lebih ringkas dan kaya makna.
    * Skor kemiripan (similarity score) yang lebih tinggi (mendekati 1) menunjukkan bahwa dua produk secara konseptual sangat mirip, bahkan jika tidak menggunakan kata kunci yang identik.

* **Hasil rekomendasi untuk produk acuan (Produk 64):**
    * Produk dengan skor kemiripan tertinggi (peringkat 0 dan 1) sangat relevan, cocok dengan konsep inti seperti bahan `suede` dan gaya `luxurious`.
    * Hasilnya **mengkonfirmasi dan memvalidasi** temuan dari model TF-IDF, karena menghasilkan daftar dan urutan rekomendasi yang sama persis, yang menunjukkan keandalan sistem.
    * Perbedaan halus seperti penggantian bahan (`nylon`) atau gaya (`executive`) juga berhasil ditangkap dan diberi skor kemiripan yang sedikit lebih rendah secara akurat.

* **Visualisasi skor kemiripan LSA:**
    * Grafik batang dengan jelas menunjukkan urutan rekomendasi dari yang paling mirip (skor tertinggi) hingga yang kurang mirip.
    * Membuktikan bahwa sistem LSA mampu mengurutkan produk secara logis berdasarkan tingkat kemiripan konseptual yang diukurnya.

### **Kesimpulan:**

* Sistem rekomendasi berbasis LSA terbukti **sangat efektif dan andal**, mampu menangkap makna semantik dari deskripsi produk untuk memberikan rekomendasi yang relevan.
* Konsistensi hasilnya dengan metode TF-IDF menunjukkan bahwa sistem ini **robust**. LSA memberikan fondasi yang lebih kuat untuk menangani sinonim dan variasi bahasa yang lebih kompleks.
* LSA merupakan peningkatan dari TF-IDF dan menjadi pilihan yang lebih baik untuk sistem skala besar, dengan potensi pengembangan untuk digabungkan menjadi sistem *hybrid* yang juga memanfaatkan data pengguna.
"""